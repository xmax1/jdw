/home/amawi/.conda/envs/dex/lib/python3.10/site-packages/jax/linear_util.py:168: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in linspace is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.
  ans = self.f(*args, **dict(self.params, **kwargs))
/home/amawi/.conda/envs/dex/lib/python3.10/site-packages/jax/_src/numpy/lax_numpy.py:2192: UserWarning: Explicitly requested dtype float64 requested in asarray is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.
  start = asarray(start, dtype=computation_dtype)
/home/amawi/.conda/envs/dex/lib/python3.10/site-packages/jax/_src/numpy/lax_numpy.py:2193: UserWarning: Explicitly requested dtype float64 requested in asarray is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.
  stop = asarray(stop, dtype=computation_dtype)
/home/amawi/.conda/envs/dex/lib/python3.10/site-packages/jax/_src/numpy/lax_numpy.py:2209: UserWarning: Explicitly requested dtype float64 requested in astype is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.
  step = step.astype(computation_dtype)
  0%|          | 0/12000 [00:00<?, ?it/s]2022-11-01 16:56:31.720084: W external/org_tensorflow/tensorflow/compiler/xla/service/gpu/gpu_conv_algorithm_picker.cc:729] None of the algorithms provided by cuDNN heuristics worked; trying fallback algorithms.  Conv: (f32[128,28,28,384]{2,1,3,0}, u8[0]{0}) custom-call(f32[128,28,28,64]{2,1,3,0}, f32[1,1,64,384]{1,0,2,3}), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
